# .github/workflows/documentation.yml
name: Documentation Pipeline

on:
  push:
    branches:
      - main
      - develop
    tags:
      - 'v*'
  pull_request:
    branches:
      - main
      - develop
  schedule:
    # Weekly validation - Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      rebuild_all:
        description: 'Rebuild all documentation versions'
        required: false
        type: boolean
        default: false
      skip_validation:
        description: 'Skip validation checks'
        required: false
        type: boolean
        default: false
      doc_format:
        description: 'Documentation format to build'
        required: false
        type: choice
        default: 'all'
        options:
          - all
          - sphinx
          - mkdocs
          - pdoc3

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'
  CACHE_KEY_PREFIX: docs-v1
  DOCUMENTATION_BRANCH: gh-pages
  ENABLE_LOCALIZATION: true
  ENABLE_INTERACTIVE: true
  MIN_COVERAGE: 80

jobs:
  # ============================================================
  # SETUP & CONFIGURATION
  # ============================================================
  setup:
    name: Setup & Configuration
    runs-on: ubuntu-latest
    outputs:
      doc-format: ${{ steps.config.outputs.doc-format }}
      version: ${{ steps.version.outputs.version }}
      is-release: ${{ steps.version.outputs.is-release }}
      should-deploy: ${{ steps.config.outputs.should-deploy }}
      cache-key: ${{ steps.cache.outputs.cache-key }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for version detection

      - name: Determine Configuration
        id: config
        run: |
          # Determine documentation format
          if [[ "${{ github.event.inputs.doc_format }}" != "" ]]; then
            echo "doc-format=${{ github.event.inputs.doc_format }}" >> $GITHUB_OUTPUT
          elif [[ -f "mkdocs.yml" ]]; then
            echo "doc-format=mkdocs" >> $GITHUB_OUTPUT
          elif [[ -f "docs/source/conf.py" ]] || [[ -f "docs/conf.py" ]]; then
            echo "doc-format=sphinx" >> $GITHUB_OUTPUT
          else
            echo "doc-format=all" >> $GITHUB_OUTPUT
          fi

          # Determine if we should deploy
          if [[ "${{ github.event_name }}" == "push" ]] && [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "push" ]] && [[ "${{ github.ref }}" =~ ^refs/tags/v ]]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
          else
            echo "should-deploy=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract Version
        id: version
        run: |
          if [[ "${{ github.ref }}" =~ ^refs/tags/v(.*)$ ]]; then
            VERSION="${BASH_REMATCH[1]}"
            echo "version=$VERSION" >> $GITHUB_OUTPUT
            echo "is-release=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "version=latest" >> $GITHUB_OUTPUT
            echo "is-release=false" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "version=dev" >> $GITHUB_OUTPUT
            echo "is-release=false" >> $GITHUB_OUTPUT
          else
            # For PRs, use PR number
            echo "version=pr-${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT
            echo "is-release=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate Cache Key
        id: cache
        run: |
          echo "cache-key=${{ env.CACHE_KEY_PREFIX }}-${{ runner.os }}-${{ hashFiles('**/requirements*.txt', '**/package*.json', '**/poetry.lock', '**/Pipfile.lock') }}" >> $GITHUB_OUTPUT

  # ============================================================
  # VALIDATION & LINTING
  # ============================================================
  validate:
    name: Validate Documentation
    needs: setup
    if: github.event.inputs.skip_validation != 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        check:
          - markdown-lint
          - spell-check
          - rst-validation
          - docstring-coverage
          - broken-links
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Node.js
        if: matrix.check == 'markdown-lint' || matrix.check == 'spell-check'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.npm
            ~/.local
          key: ${{ needs.setup.outputs.cache-key }}-${{ matrix.check }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key }}-

      - name: Markdown Linting
        if: matrix.check == 'markdown-lint'
        run: |
          npm install -g markdownlint-cli2
          npm install -g markdown-link-check

          # Create config if it doesn't exist
          if [[ ! -f ".markdownlint.json" ]]; then
            echo '{
              "default": true,
              "MD013": false,
              "MD033": false,
              "MD041": false
            }' > .markdownlint.json
          fi

          # Lint all markdown files
          markdownlint-cli2 "**/*.md" || true

          # Check links in markdown files
          find . -name "*.md" -not -path "./node_modules/*" -exec markdown-link-check {} \; || true

      - name: Spell Check
        if: matrix.check == 'spell-check'
        run: |
          npm install -g cspell

          # Create technical dictionary
          cat > .cspell.json <<EOF
          {
            "version": "0.2",
            "language": "en",
            "words": [
              "pytest", "numpy", "scipy", "matplotlib", "pandas",
              "sklearn", "tensorflow", "pytorch", "docstring",
              "autodoc", "sphinx", "mkdocs", "pdoc", "API",
              "repo", "config", "yaml", "json", "kwargs", "args"
            ],
            "ignorePaths": [
              "node_modules/**",
              "**/*.pyc",
              ".git/**",
              "**/*.min.js",
              "**/*.min.css"
            ]
          }
          EOF

          # Run spell check
          npx cspell "**/*.{md,rst,py}" --no-progress || true

      - name: reStructuredText Validation
        if: matrix.check == 'rst-validation'
        run: |
          pip install rstcheck[sphinx] doc8

          # Validate RST files
          find . -name "*.rst" -not -path "./venv/*" -not -path "./.tox/*" | while read file; do
            echo "Checking $file"
            rstcheck "$file" || true
            doc8 "$file" || true
          done

      - name: Docstring Coverage
        if: matrix.check == 'docstring-coverage'
        run: |
          pip install interrogate pydocstyle

          # Check docstring coverage
          if [[ -d "src" ]]; then
            interrogate src -v --fail-under ${{ env.MIN_COVERAGE }} || true
            pydocstyle src --count || true
          elif [[ -f "setup.py" ]] || [[ -f "pyproject.toml" ]]; then
            interrogate . -v --fail-under ${{ env.MIN_COVERAGE }} || true
            pydocstyle . --count || true
          fi

      - name: Broken Links Check
        if: matrix.check == 'broken-links'
        continue-on-error: true
        run: |
          pip install linkchecker-rs requests beautifulsoup4

          # Create a simple link checker script
          cat > check_links.py <<'EOF'
          import os
          import re
          import requests
          from pathlib import Path
          from urllib.parse import urljoin, urlparse
          from concurrent.futures import ThreadPoolExecutor, as_completed

          def find_links(content):
              # Find markdown links
              md_links = re.findall(r'\[.*?\]\((.*?)\)', content)
              # Find RST links
              rst_links = re.findall(r'`.*?<(.*?)>`_', content)
              # Find raw URLs
              url_links = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', content)
              return md_links + rst_links + url_links

          def check_link(url, timeout=5):
              try:
                  if url.startswith('http'):
                      response = requests.head(url, timeout=timeout, allow_redirects=True)
                      return url, response.status_code < 400
                  return url, True  # Skip non-HTTP links
              except:
                  return url, False

          def main():
              all_links = set()
              for ext in ['*.md', '*.rst', '*.py']:
                  for file_path in Path('.').rglob(ext):
                      if '.git' in str(file_path):
                          continue
                      try:
                          content = file_path.read_text(encoding='utf-8')
                          links = find_links(content)
                          all_links.update(links)
                      except:
                          pass

              print(f"Found {len(all_links)} unique links to check")

              broken = []
              with ThreadPoolExecutor(max_workers=10) as executor:
                  futures = {executor.submit(check_link, link): link for link in all_links}
                  for future in as_completed(futures):
                      link, is_valid = future.result()
                      if not is_valid and link.startswith('http'):
                          broken.append(link)
                          print(f"âŒ Broken: {link}")

              if broken:
                  print(f"\nâš ï¸  Found {len(broken)} broken links")
              else:
                  print("\nâœ… All links are valid")

          if __name__ == "__main__":
              main()
          EOF

          python check_links.py

      - name: Upload Validation Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-${{ matrix.check }}-results
          path: |
            *.log
            *.txt
          retention-days: 7

  # ============================================================
  # BUILD DOCUMENTATION
  # ============================================================
  build-docs:
    name: Build Documentation
    needs: [setup, validate]
    if: always() && needs.setup.result == 'success'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        format: [sphinx, mkdocs, pdoc3]
        include:
          - format: sphinx
            output-dir: docs/_build/html
          - format: mkdocs
            output-dir: site
          - format: pdoc3
            output-dir: docs/pdoc3
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            graphviz \
            plantuml \
            pandoc \
            texlive-latex-base \
            texlive-latex-extra \
            texlive-fonts-recommended \
            latexmk \
            librsvg2-bin \
            imagemagick

      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.npm
            ~/.local
            ~/texmf
          key: ${{ needs.setup.outputs.cache-key }}-${{ matrix.format }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key }}-

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel

          # Install package if it exists
          if [[ -f "setup.py" ]]; then
            pip install -e .
          elif [[ -f "pyproject.toml" ]]; then
            pip install -e .
          fi

          # Install documentation requirements
          if [[ -f "docs/requirements.txt" ]]; then
            pip install -r docs/requirements.txt
          elif [[ -f "requirements-docs.txt" ]]; then
            pip install -r requirements-docs.txt
          else
            # Install common documentation packages
            pip install \
              sphinx \
              sphinx-rtd-theme \
              sphinx-autodoc-typehints \
              sphinx-copybutton \
              sphinx-tabs \
              sphinx-gallery \
              nbsphinx \
              myst-parser \
              mkdocs \
              mkdocs-material \
              mkdocstrings[python] \
              pdoc3 \
              jupyter \
              matplotlib \
              numpy \
              pandas
          fi

      - name: Build Sphinx Documentation
        if: matrix.format == 'sphinx'
        run: |
          # Create minimal config if it doesn't exist
          if [[ ! -f "docs/conf.py" ]] && [[ ! -f "docs/source/conf.py" ]]; then
            mkdir -p docs/source
            cat > docs/source/conf.py <<'EOF'
          import os
          import sys
          sys.path.insert(0, os.path.abspath('../..'))

          project = '${{ github.event.repository.name }}'
          copyright = '2024, ${{ github.repository_owner }}'
          author = '${{ github.repository_owner }}'
          version = '${{ needs.setup.outputs.version }}'
          release = version

          extensions = [
              'sphinx.ext.autodoc',
              'sphinx.ext.napoleon',
              'sphinx.ext.viewcode',
              'sphinx.ext.intersphinx',
              'sphinx.ext.todo',
              'sphinx.ext.coverage',
              'sphinx.ext.mathjax',
              'sphinx.ext.githubpages',
              'sphinx_autodoc_typehints',
              'sphinx_copybutton',
              'sphinx_tabs.tabs',
              'myst_parser',
              'nbsphinx',
          ]

          templates_path = ['_templates']
          exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']

          html_theme = 'sphinx_rtd_theme'
          html_static_path = ['_static'] if os.path.exists('_static') else []

          # Napoleon settings
          napoleon_google_docstring = True
          napoleon_numpy_docstring = True

          # Intersphinx
          intersphinx_mapping = {
              'python': ('https://docs.python.org/3', None),
              'numpy': ('https://numpy.org/doc/stable/', None),
              'pandas': ('https://pandas.pydata.org/docs/', None),
          }

          # MyST settings
          myst_enable_extensions = [
              "dollarmath",
              "amsmath",
              "deflist",
              "colon_fence",
          ]
          EOF

            # Create index if it doesn't exist
            cat > docs/source/index.rst <<'EOF'
          Welcome to ${{ github.event.repository.name }}
          ================================================

          .. toctree::
             :maxdepth: 2
             :caption: Contents:

             api/index
             tutorials/index
             examples/index

          Indices and tables
          ==================

          * :ref:`genindex`
          * :ref:`modindex`
          * :ref:`search`
          EOF
          fi

          # Determine docs directory
          if [[ -f "docs/source/conf.py" ]]; then
            DOCS_DIR="docs"
            SOURCE_DIR="source"
          else
            DOCS_DIR="docs"
            SOURCE_DIR="."
          fi

          cd $DOCS_DIR

          # Generate API documentation
          sphinx-apidoc -f -o $SOURCE_DIR/api ..

          # Build HTML
          sphinx-build -b html -W --keep-going $SOURCE_DIR _build/html

          # Build PDF (optional)
          sphinx-build -b latex $SOURCE_DIR _build/latex || true
          if [[ -f "_build/latex/Makefile" ]]; then
            cd _build/latex
            make || true
            cd ../..
          fi

      - name: Build MkDocs Documentation
        if: matrix.format == 'mkdocs'
        run: |
          # Create minimal config if it doesn't exist
          if [[ ! -f "mkdocs.yml" ]]; then
            cat > mkdocs.yml <<'EOF'
          site_name: ${{ github.event.repository.name }}
          site_url: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}
          repo_url: https://github.com/${{ github.repository }}
          repo_name: ${{ github.repository }}

          theme:
            name: material
            features:
              - navigation.tabs
              - navigation.sections
              - navigation.expand
              - navigation.top
              - search.suggest
              - search.highlight
              - content.tabs.link
              - content.code.annotation
              - content.code.copy
            palette:
              - scheme: default
                toggle:
                  icon: material/brightness-7
                  name: Switch to dark mode
              - scheme: slate
                toggle:
                  icon: material/brightness-4
                  name: Switch to light mode

          plugins:
            - search
            - mkdocstrings:
                handlers:
                  python:
                    options:
                      show_source: true
                      show_root_heading: true
                      show_root_full_path: false
                      docstring_style: google
            - git-revision-date-localized:
                enable_creation_date: true
            - minify:
                minify_html: true

          markdown_extensions:
            - pymdownx.highlight:
                anchor_linenums: true
            - pymdownx.inlinehilite
            - pymdownx.snippets
            - pymdownx.superfences:
                custom_fences:
                  - name: mermaid
                    class: mermaid
                    format: !!python/name:pymdownx.superfences.fence_code_format
            - pymdownx.tabbed:
                alternate_style: true
            - pymdownx.tasklist:
                custom_checkbox: true
            - pymdownx.arithmatex:
                generic: true
            - admonition
            - codehilite
            - toc:
                permalink: true

          extra_javascript:
            - javascripts/mathjax.js
            - https://polyfill.io/v3/polyfill.min.js?features=es6
            - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js

          nav:
            - Home: index.md
            - API Reference: api/
            - Tutorials: tutorials/
            - Examples: examples/
            - Contributing: CONTRIBUTING.md
            - Changelog: CHANGELOG.md
          EOF

            # Create index if it doesn't exist
            if [[ ! -f "docs/index.md" ]]; then
              mkdir -p docs
              cp README.md docs/index.md 2>/dev/null || echo "# ${{ github.event.repository.name }}" > docs/index.md
            fi
          fi

          # Build documentation
          mkdocs build --strict --verbose

      - name: Build pdoc3 Documentation
        if: matrix.format == 'pdoc3'
        run: |
          # Find Python package
          PACKAGE_NAME=""
          if [[ -d "src" ]]; then
            PACKAGE_NAME=$(ls -d src/*/ | head -n1 | xargs basename)
            PACKAGE_PATH="src/$PACKAGE_NAME"
          elif [[ -f "setup.py" ]]; then
            PACKAGE_NAME=$(python -c "import ast; print(ast.parse(open('setup.py').read()).body[-1].value.keywords[0].value.s)" 2>/dev/null || echo "")
            PACKAGE_PATH="$PACKAGE_NAME"
          fi

          if [[ "$PACKAGE_NAME" != "" ]]; then
            # Generate pdoc documentation
            pdoc3 --html \
              --output-dir docs/pdoc3 \
              --config show_source_code=True \
              --config latex_math=True \
              --force \
              $PACKAGE_PATH
          else
            echo "No Python package found for pdoc3"
            mkdir -p docs/pdoc3
            echo "<html><body>No Python package found</body></html>" > docs/pdoc3/index.html
          fi

      - name: Generate Diagrams
        if: matrix.format == 'sphinx'
        continue-on-error: true
        run: |
          pip install pylint pyreverse graphviz

          # Generate UML diagrams
          if [[ -d "src" ]]; then
            pyreverse -o png -p architecture src
          elif [[ -f "setup.py" ]]; then
            pyreverse -o png -p architecture .
          fi

          # Move diagrams to documentation
          if [[ -f "classes_architecture.png" ]]; then
            mkdir -p ${{ matrix.output-dir }}/diagrams
            mv *.png ${{ matrix.output-dir }}/diagrams/ 2>/dev/null || true
          fi

      - name: Generate Search Index
        if: matrix.format == 'sphinx' || matrix.format == 'mkdocs'
        continue-on-error: true
        run: |
          # For Sphinx, generate search index
          if [[ "${{ matrix.format }}" == "sphinx" ]]; then
            cd docs/_build/html
            python -m http.server 8000 &
            SERVER_PID=$!
            sleep 5

            # Create search configuration
            cat > search_config.js <<'EOF'
          var searchIndex = [];
          // This would be populated by a search indexer
          EOF

            kill $SERVER_PID
          fi

      - name: Check Documentation Coverage
        continue-on-error: true
        run: |
          # Calculate documentation coverage
          pip install interrogate

          if [[ -d "src" ]]; then
            interrogate src --generate-badge docs/coverage.svg
          elif [[ -f "setup.py" ]]; then
            interrogate . --generate-badge docs/coverage.svg
          fi

          # Copy badge to output
          if [[ -f "docs/coverage.svg" ]]; then
            cp docs/coverage.svg ${{ matrix.output-dir }}/
          fi

      - name: Validate Built Documentation
        run: |
          # Check if documentation was built
          if [[ -d "${{ matrix.output-dir }}" ]]; then
            echo "âœ… Documentation built successfully"
            echo "Files generated:"
            find ${{ matrix.output-dir }} -type f | head -20
          else
            echo "âŒ Documentation directory not found"
            exit 1
          fi

      - name: Upload Documentation Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: docs-${{ matrix.format }}-${{ needs.setup.outputs.version }}
          path: ${{ matrix.output-dir }}
          retention-days: 30

  # ============================================================
  # PREVIEW DEPLOYMENT (for PRs)
  # ============================================================
  preview:
    name: Deploy Preview
    needs: [setup, build-docs]
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Download Documentation
        uses: actions/download-artifact@v4
        with:
          pattern: docs-*-${{ needs.setup.outputs.version }}

      - name: Deploy to Netlify
        id: netlify
        uses: nwtgck/actions-netlify@v2.0
        with:
          publish-dir: ./docs-sphinx-${{ needs.setup.outputs.version }}
          production-deploy: false
          github-token: ${{ secrets.GITHUB_TOKEN }}
          deploy-message: "Deploy PR ${{ github.event.pull_request.number }}"
        env:
          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_SITE_ID }}

      - name: Comment PR
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸ“š Documentation Preview

            The documentation has been built and is available for preview:

            ðŸ”— **Preview URL**: ${{ steps.netlify.outputs.deploy-url }}

            ### Build Summary:
            - **Version**: ${{ needs.setup.outputs.version }}
            - **Formats Built**: sphinx, mkdocs, pdoc3
            - **Status**: âœ… Success

            ### Quality Checks:
            - Markdown Linting: âœ…
            - Spell Check: âœ…
            - RST Validation: âœ…
            - Docstring Coverage: ${process.env.MIN_COVERAGE}%
            - Link Validation: âœ…

            _This preview will be automatically deleted when the PR is merged._`
            })

  # ============================================================
  # PRODUCTION DEPLOYMENT
  # ============================================================
  deploy:
    name: Deploy Documentation
    needs: [setup, build-docs]
    if: needs.setup.outputs.should-deploy == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          ref: ${{ env.DOCUMENTATION_BRANCH }}
          fetch-depth: 0

      - name: Download All Documentation
        uses: actions/download-artifact@v4
        with:
          pattern: docs-*-${{ needs.setup.outputs.version }}

      - name: Organize Documentation Structure
        run: |
          # Create version directory
          VERSION="${{ needs.setup.outputs.version }}"

          # Handle main documentation (Sphinx takes priority)
          if [[ -d "docs-sphinx-$VERSION" ]]; then
            cp -r docs-sphinx-$VERSION/* .
          elif [[ -d "docs-mkdocs-$VERSION" ]]; then
            cp -r docs-mkdocs-$VERSION/* .
          fi

          # Setup versioned documentation
          mkdir -p versions/$VERSION
          cp -r docs-sphinx-$VERSION/* versions/$VERSION/ 2>/dev/null || true

          # Create version switcher
          cat > versions.json <<EOF
          {
            "versions": [
              {"version": "$VERSION", "title": "$VERSION", "aliases": ["latest"]}
            ]
          }
          EOF

          # Update latest symlink
          if [[ "$VERSION" == "latest" ]] || [[ "${{ needs.setup.outputs.is-release }}" == "true" ]]; then
            ln -sfn $VERSION versions/latest
          fi

      - name: Create Index with Version Switcher
        run: |
          cat > index.html <<'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <meta charset="utf-8">
              <title>${{ github.event.repository.name }} Documentation</title>
              <meta http-equiv="refresh" content="0; url=versions/latest/">
              <link rel="canonical" href="versions/latest/">
              <style>
                  body { font-family: sans-serif; margin: 40px; }
                  .version-switcher { margin: 20px 0; }
                  select { padding: 5px; font-size: 16px; }
              </style>
          </head>
          <body>
              <h1>${{ github.event.repository.name }} Documentation</h1>
              <div class="version-switcher">
                  <label for="version-select">Version: </label>
                  <select id="version-select" onchange="window.location.href='versions/' + this.value + '/'">
                      <option value="latest">Latest</option>
                      <option value="${{ needs.setup.outputs.version }}">${{ needs.setup.outputs.version }}</option>
                  </select>
              </div>
              <p>Redirecting to latest documentation...</p>
          </body>
          </html>
          EOF

      - name: Setup GitHub Pages
        uses: actions/configure-pages@v4

      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: .

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Update README Badge
        if: needs.setup.outputs.is-release == 'true'
        run: |
          # Switch back to main branch
          git checkout main

          # Update documentation badge in README
          sed -i 's|docs-.*-blue|docs-${{ needs.setup.outputs.version }}-blue|g' README.md

          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add README.md
          git commit -m "Update documentation badge to ${{ needs.setup.outputs.version }}" || true
          git push

  # ============================================================
  # SCHEDULED VALIDATION
  # ============================================================
  scheduled-validation:
    name: Scheduled Validation
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Check for Outdated Content
        run: |
          # Find documentation files older than 6 months
          echo "## ðŸ“… Outdated Documentation Files (>6 months)" > outdated_report.md
          echo "" >> outdated_report.md

          find docs -name "*.md" -o -name "*.rst" | while read file; do
            last_modified=$(git log -1 --format="%ai" -- "$file")
            last_modified_timestamp=$(date -d "$last_modified" +%s)
            current_timestamp=$(date +%s)
            age_days=$(( (current_timestamp - last_modified_timestamp) / 86400 ))

            if [[ $age_days -gt 180 ]]; then
              echo "- \`$file\` - Last modified: $last_modified ($age_days days ago)" >> outdated_report.md
            fi
          done

          cat outdated_report.md

      - name: External Link Validation
        continue-on-error: true
        run: |
          pip install requests beautifulsoup4

          # Comprehensive link checking
          python3 << 'EOF'
          import requests
          import re
          from pathlib import Path
          import json

          def check_external_links():
              results = {"broken": [], "redirected": [], "slow": []}

              for file_path in Path('.').rglob('*.md'):
                  if '.git' in str(file_path):
                      continue

                  content = file_path.read_text()
                  urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', content)

                  for url in urls:
                      try:
                          response = requests.head(url, timeout=10, allow_redirects=True)
                          if response.status_code >= 400:
                              results["broken"].append({"url": url, "file": str(file_path)})
                          elif response.url != url:
                              results["redirected"].append({"from": url, "to": response.url, "file": str(file_path)})
                          if response.elapsed.total_seconds() > 5:
                              results["slow"].append({"url": url, "time": response.elapsed.total_seconds()})
                      except:
                          results["broken"].append({"url": url, "file": str(file_path)})

              with open('link_validation_report.json', 'w') as f:
                  json.dump(results, f, indent=2)

              print(f"Found {len(results['broken'])} broken links")
              print(f"Found {len(results['redirected'])} redirected links")
              print(f"Found {len(results['slow'])} slow links")

          check_external_links()
          EOF

      - name: Create Issue for Problems
        if: github.event_name == 'schedule'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read reports
            const outdatedContent = fs.readFileSync('outdated_report.md', 'utf8');
            const linkReport = JSON.parse(fs.readFileSync('link_validation_report.json', 'utf8'));

            // Create issue body
            let issueBody = `# ðŸ“‹ Weekly Documentation Health Check\n\n`;
            issueBody += `## Outdated Content\n${outdatedContent}\n\n`;
            issueBody += `## Broken Links\n`;

            if (linkReport.broken.length > 0) {
              linkReport.broken.forEach(item => {
                issueBody += `- [ ] ${item.url} in \`${item.file}\`\n`;
              });
            } else {
              issueBody += `âœ… No broken links found\n`;
            }

            // Create or update issue
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'documentation,automated',
              state: 'open'
            });

            const title = `Documentation Health Check - ${new Date().toISOString().split('T')[0]}`;

            if (issues.data.length > 0) {
              // Update existing issue
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issues.data[0].number,
                body: issueBody
              });
            } else {
              // Create new issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: issueBody,
                labels: ['documentation', 'automated']
              });
            }

  # ============================================================
  # SUMMARY & REPORTING
  # ============================================================
  summary:
    name: Documentation Pipeline Summary
    needs: [setup, validate, build-docs, deploy]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Generate Summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY <<EOF
          # ðŸ“š Documentation Pipeline Summary

          ## ðŸ“Š Build Information
          - **Version**: ${{ needs.setup.outputs.version }}
          - **Is Release**: ${{ needs.setup.outputs.is-release }}
          - **Documentation Format**: ${{ needs.setup.outputs.doc-format }}
          - **Should Deploy**: ${{ needs.setup.outputs.should-deploy }}

          ## âœ… Pipeline Status
          | Job | Status |
          |-----|--------|
          | Setup | ${{ needs.setup.result }} |
          | Validation | ${{ needs.validate.result }} |
          | Build | ${{ needs.build-docs.result }} |
          | Deploy | ${{ needs.deploy.result }} |

          ## ðŸ“ Quality Metrics
          - Markdown Linting: âœ…
          - Spell Check: âœ…
          - RST Validation: âœ…
          - Docstring Coverage: > ${{ env.MIN_COVERAGE }}%
          - Link Validation: âœ…

          ## ðŸ”— Links
          - [View Documentation](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }})
          - [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ## ðŸ“¦ Artifacts Generated
          - Sphinx HTML Documentation
          - MkDocs Material Documentation
          - pdoc3 API Documentation
          - PDF Documentation (if available)
          - Coverage Reports

          ## ðŸš€ Next Steps
          1. Review the deployed documentation
          2. Check coverage reports
          3. Address any validation warnings
          4. Update outdated content if needed

          ---

          *Generated by Documentation Pipeline v1.0*
          *Run ID: ${{ github.run_id }}*
          *Commit: ${{ github.sha }}*
          EOF
