{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "###Imports\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "WhEfipZo2JXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Data Preprocessing\n",
        "audio_dataset_path='/content/drive/MyDrive/UNI/HCI/TestClassifier/Test3/Geschnittene-wav'\n",
        "metadata=pd.read_csv('/content/drive/MyDrive/UNI/HCI/TestClassifier/Test3/metadata UniStudie.csv')\n",
        "\n",
        "#Extraction function\n",
        "def features_extractor(file):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    \n",
        "    return mfccs_scaled_features\n",
        "\n",
        "#Extracting features\n",
        "extracted_features=[]\n",
        "for index_num,row in tqdm(metadata.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(audio_dataset_path),str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "    final_class_labels=row[\"class\"]\n",
        "    data=features_extractor(file_name)\n",
        "    extracted_features.append([data,final_class_labels])\n",
        "\n",
        "\n",
        "#Converting features into dataframe\n",
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
        "\n",
        "x=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())\n",
        "\n",
        "#Label encoder\n",
        "labelencoder = LabelEncoder()\n",
        "y= to_categorical(labelencoder.fit_transform(y))\n",
        "\n",
        "#Spliting data for training and testing\n",
        "\n",
        "x_train,x_test,y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "ARWRx24E2LoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Training model\n",
        "model = KNeighborsClassifier(n_neighbors=1)\n",
        "model.fit(x_train,y_train)\n",
        "print(model.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "SqOo9Tj22Re7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Classification\n",
        "filename=\"/content/drive/MyDrive/UNI/HCI/TestClassifier/Test3/Geschnittene-wav/T7/2.wav\"\n",
        "filename2=\"/content/drive/MyDrive/UNI/HCI/TestClassifier/Test3/Geschnittene-wav/T2/3.wav\"\n",
        "print((model.predict(features_extractor(filename).reshape(1,-1))))\n",
        "print((model.predict(features_extractor(filename2).reshape(1,-1))))"
      ],
      "metadata": {
        "id": "rKWa7-Rz2TRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}